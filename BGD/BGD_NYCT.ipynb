{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315a53da",
   "metadata": {},
   "source": [
    "# Projekt BGD \n",
    "## Wykorzystanie Sparka w ML\n",
    "\n",
    "1. Problem: Predykcja czasu przejazdu taksówką na podstawie danych o godzinie i dniu wyjazdu, kierunku i długości trasy.\n",
    "2. Dane: https://www.kaggle.com/datasets/kentonnlp/2014-new-york-city-taxi-trips\n",
    "3. Model: Gradient Boosted Trees Regressor.\n",
    "4. Ewauacja: R^2, MAE, RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23697ab9",
   "metadata": {},
   "source": [
    "### Wykorzystywane moduły"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6bd782e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "from pyspark.sql.functions import count, unix_timestamp, udf, col, lit, dayofweek, hour, to_date, date_format, atan2\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02028ee5",
   "metadata": {},
   "source": [
    "### Zainicjowanie sesji sparkowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d0039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"Big Data Project\") \\\n",
    "             .setMaster(\"local[*]\") \\\n",
    "            .set(\"spark.executor.memory\", \"16g\") \\\n",
    "            .set(\"spark.executor.cores\", \"8\") \\\n",
    "            .set(\"spark.executor.instances\", \"4\") \\\n",
    "            .set(\"spark.driver.memory\", \"4g\") \\\n",
    "            .set(\"spark.driver.maxResultSize\", \"1M\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ec9279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://lab-m:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Big Data Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x253b672b970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ebda6",
   "metadata": {},
   "source": [
    "### Pobranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "238ee419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_nyc_data = f'{os.getcwd()}/NYCT/nyc_taxi_data_2014.csv'\n",
    "df_nyc = spark.read.option('header',True).csv(path_nyc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef044736",
   "metadata": {},
   "source": [
    "### Wstepne przetwarzanie i analiza danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e4844ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_nyc_data = f'{os.getcwd()}/NYCT/nyc_taxi_data_2014.csv'\n",
    "df_nyc = spark.read.option('header',True).csv(path_nyc_data)\n",
    "\n",
    "\n",
    "df = df_nyc.select('trip_distance','pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                   'dropoff_latitude','dropoff_datetime','pickup_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4bdfcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- direction: double (nullable = true)\n",
      " |-- week_day: double (nullable = true)\n",
      " |-- hour: double (nullable = true)\n",
      " |-- travel_time: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('pickup_longitude', col('pickup_longitude').cast('float'))\\\n",
    "        .withColumn('pickup_latitude', col('pickup_latitude').cast('float'))\\\n",
    "        .withColumn('dropoff_longitude', col('dropoff_longitude').cast('float'))\\\n",
    "        .withColumn('dropoff_latitude', col('dropoff_latitude').cast('float'))\n",
    "# Funkcja atan2 jest funkcją matematyczną, która oblicza arcustangens z dwóch podanych argumentów.\n",
    "# W przypadku zastosowań geograficznych, taka funkcja może być wykorzystywana do obliczenia kąta kierunku \n",
    "# pomiędzy dwoma punktami na płaszczyźnie.\n",
    "df = df.withColumn(\"direction\", atan2(col(\"dropoff_latitude\") - col(\"pickup_latitude\"), col(\"dropoff_longitude\") - col(\"pickup_longitude\")))\n",
    "\n",
    "df = df.withColumn('week_day', dayofweek(col('pickup_datetime')).cast('integer'))\n",
    "df = df.withColumn('hour', hour(col('pickup_datetime')))\n",
    "\n",
    "df = df.withColumn('pickup_datetime', unix_timestamp(col('pickup_datetime'), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df = df.withColumn('dropoff_datetime', unix_timestamp(col('dropoff_datetime'), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "df = df.withColumn('trip_distance', col('trip_distance'))\n",
    "\n",
    "df = df.withColumn('travel_time', (col('dropoff_datetime')-col('pickup_datetime'))/60)\n",
    "\n",
    "# vectorassembler potrzebuje na wejsciu double, nie jest kompatybilny z floatem\n",
    "df = df.select([col(c).cast(\"double\") for c in df.columns]) \n",
    "\n",
    "df = df.select('trip_distance', 'direction', 'week_day', 'hour', 'travel_time')\n",
    "\n",
    "df = df.filter(col(\"travel_time\") > 0)\n",
    "df = df.na.drop()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "791989fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+------------------+------------------+--------------------+\n",
      "|summary|     trip_distance|           direction|          week_day|              hour|         travel_time|\n",
      "+-------+------------------+--------------------+------------------+------------------+--------------------+\n",
      "|  count|          14957348|            14957348|          14957348|          14957348|            14957348|\n",
      "|   mean|2.7992152205057192|-0.22357213133880377| 4.127336543884651|13.573190447932348|    12.3708147549507|\n",
      "| stddev| 3.326338806698982|  1.7269145057393407|1.9477535472357383| 6.435122011311211|  11.447761103243032|\n",
      "|    min|               0.0| -3.1415907789759636|               1.0|               0.0|0.016666666666666666|\n",
      "|    max|             100.0|   3.141592653589793|               7.0|              23.0|             19517.3|\n",
      "+-------+------------------+--------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c06db1",
   "metadata": {},
   "source": [
    "### Normalizacja min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "fff96676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "input_cols = [c for c in df.columns if c != 'travel_time']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(df)\n",
    "\n",
    "# inicjalizacja scalera jako min-max\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"normalized_features\")\n",
    "\n",
    "# dopasowanie scalera do danych\n",
    "scaler_model = scaler.fit(assembled_df)\n",
    "\n",
    "# normalizacja \n",
    "normalized_df = scaler_model.transform(assembled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3273d17",
   "metadata": {},
   "source": [
    "### Podzial danych na zb treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2bc6844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  11963986\n",
      "Test dataset :  2993362\n"
     ]
    }
   ],
   "source": [
    "final_df = normalized_df.select('normalized_features', 'travel_time')\n",
    "train_df, test_df = final_df.randomSplit([0.8,0.2], seed=96)\n",
    "\n",
    "print('Train dataset: ', train_df.count())\n",
    "print('Test dataset : ', test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6c87e",
   "metadata": {},
   "source": [
    "### Modelowanie GBTRegressor (Gradient Boosted Trees Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "85270625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|       travel_time|        prediction|\n",
      "+------------------+------------------+\n",
      "|1.2833333333333334|3.9726587138471023|\n",
      "|              4.55|3.7001944230797004|\n",
      "|1.1166666666666667| 3.157236820521912|\n",
      "| 4.366666666666666|3.3622604332798227|\n",
      "|             13.05| 3.927278857335151|\n",
      "+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# obiekt GBTRegressor\n",
    "gbm = GBTRegressor(featuresCol='normalized_features', labelCol='travel_time')\n",
    "\n",
    "# dopasowanie modelu do danych treningowych\n",
    "gbm_model = gbm.fit(train_df)\n",
    "\n",
    "# predykcja na zb testowym\n",
    "y_pred = gbm_model.transform(test_df)\n",
    "\n",
    "# porownanie kilku pierwszych wartosci z predykcjami\n",
    "y_pred.select('travel_time', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb1051",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3af5e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 SCORE :  0.6718378665445541\n",
      "MAE      :  3.107738758060092\n",
      "RMSE     :  5.461139887592322\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='travel_time')\n",
    "\n",
    "print('R2 SCORE : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'}))\n",
    "print('MAE      : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'}))\n",
    "print('RMSE     : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5ad0d",
   "metadata": {},
   "source": [
    "### Wylaczenie sesji sparkowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e00bd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac549fde",
   "metadata": {},
   "source": [
    "### Wnioski\n",
    "\n",
    "R^2 mówi o dopasowaniu modelu do danych, im bliżej 1 tym model jest bardziej dopasowany. \\\n",
    "W tym przypadku 67% wariancji atrybucie predykowanym travel_time wyjaniane jest przez model.\n",
    "\n",
    "MAE (Mean Absolute Error) na poziomie 3.11 daje informację o średnim bezwzględnym błędzie predykcji.\n",
    "\n",
    "RMSE (Root Mean Squared Error) równy 5.46 to pierwiastek kwadratowe z MSE (błędu średniokwadratowego).\n",
    "\n",
    "Model ma zadowalającą zdolność predykcyjną, ale istnieje margines poprawy, szczególnie w redukcji błędu RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
